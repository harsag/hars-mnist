{"metadata":{"orig_nbformat":4,"jupytext":{"split_at_heading":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#hide\n!pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()","metadata":{"gradient":{"editing":false,"id":"1c59e079-035f-4e25-9277-e2b0423ab296","kernelId":""},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install fastai\n!pip install fastcore\nfrom fastai.vision.all import *","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: fastai in /srv/conda/envs/notebook/lib/python3.7/site-packages (2.5.3)\nRequirement already satisfied: pip in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastai) (21.3.1)\nRequirement already satisfied: torchvision>=0.8.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastai) (0.11.2)\nRequirement already satisfied: torch<1.11,>=1.7.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastai) (1.10.1)\nRequirement already satisfied: requests in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastai) (2.26.0)\nRequirement already satisfied: pillow>6.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastai) (8.4.0)\nRequirement already satisfied: packaging in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastai) (21.3)\nRequirement already satisfied: scipy in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastai) (1.7.3)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastai) (0.0.5)\nRequirement already satisfied: pyyaml in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastai) (6.0)\nRequirement already satisfied: pandas in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastai) (1.3.5)\nRequirement already satisfied: scikit-learn in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastai) (1.0.1)\nRequirement already satisfied: spacy<4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastai) (3.2.1)\nRequirement already satisfied: fastprogress>=0.2.4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastai) (1.0.0)\nRequirement already satisfied: fastcore<1.4,>=1.3.22 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastai) (1.3.27)\nRequirement already satisfied: matplotlib in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastai) (3.5.1)\nRequirement already satisfied: numpy in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastprogress>=0.2.4->fastai) (1.21.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (3.0.8)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (0.7.5)\nRequirement already satisfied: pathy>=0.3.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (0.6.1)\nRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (3.10.0.2)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (2.0.6)\nRequirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (59.1.1)\nRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (0.9.0)\nRequirement already satisfied: srsly<3.0.0,>=2.4.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (2.4.2)\nRequirement already satisfied: thinc<8.1.0,>=8.0.12 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (8.0.13)\nRequirement already satisfied: jinja2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (3.0.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (1.8.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (3.3.0)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (1.0.6)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (2.0.6)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (1.0.1)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (3.0.6)\nRequirement already satisfied: typer<0.5.0,>=0.3.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (0.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from spacy<4->fastai) (4.62.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from packaging->fastai) (3.0.6)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests->fastai) (2.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests->fastai) (1.26.7)\nRequirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests->fastai) (3.1)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests->fastai) (2021.10.8)\nRequirement already satisfied: fonttools>=4.22.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib->fastai) (4.28.5)\nRequirement already satisfied: python-dateutil>=2.7 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib->fastai) (2.8.2)\nRequirement already satisfied: kiwisolver>=1.0.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib->fastai) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib->fastai) (0.11.0)\nRequirement already satisfied: pytz>=2017.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas->fastai) (2021.3)\nRequirement already satisfied: joblib>=0.11 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from scikit-learn->fastai) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from scikit-learn->fastai) (3.0.0)\nRequirement already satisfied: zipp>=0.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<4->fastai) (3.6.0)\nRequirement already satisfied: smart-open<6.0.0,>=5.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<4->fastai) (5.2.1)\nRequirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<4->fastai) (8.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jinja2->spacy<4->fastai) (2.0.1)\nRequirement already satisfied: importlib-metadata in /srv/conda/envs/notebook/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<4->fastai) (4.8.2)\nRequirement already satisfied: fastcore in /srv/conda/envs/notebook/lib/python3.7/site-packages (1.3.27)\nRequirement already satisfied: packaging in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastcore) (21.3)\nRequirement already satisfied: pip in /srv/conda/envs/notebook/lib/python3.7/site-packages (from fastcore) (21.3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from packaging->fastcore) (3.0.6)\n","output_type":"stream"}]},{"cell_type":"code","source":"#hide\nfrom fastai.vision.all import *\nfrom fastai.vision.widgets import *\nfrom fastbook import *","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(torch.__version__)","metadata":{"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"1.10.1+cu102\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch==1.6.0","metadata":{"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting torch==1.6.0\n  Using cached torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\nRequirement already satisfied: future in /srv/conda/envs/notebook/lib/python3.7/site-packages (from torch==1.6.0) (0.18.2)\nRequirement already satisfied: numpy in /srv/conda/envs/notebook/lib/python3.7/site-packages (from torch==1.6.0) (1.21.5)\nInstalling collected packages: torch\n  Attempting uninstall: torch\n    Found existing installation: torch 1.10.1\n    Uninstalling torch-1.10.1:\n      Successfully uninstalled torch-1.10.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchvision 0.11.2 requires torch==1.10.1, but you have torch 1.6.0 which is incompatible.\nfastai 2.5.3 requires torch<1.11,>=1.7.0, but you have torch 1.6.0 which is incompatible.\u001b[0m\nSuccessfully installed torch-1.6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torchvision==0.7.0","metadata":{"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting torchvision==0.7.0\n  Using cached torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9 MB)\nRequirement already satisfied: torch==1.6.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from torchvision==0.7.0) (1.6.0)\nRequirement already satisfied: pillow>=4.1.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from torchvision==0.7.0) (8.4.0)\nRequirement already satisfied: numpy in /srv/conda/envs/notebook/lib/python3.7/site-packages (from torchvision==0.7.0) (1.21.5)\nRequirement already satisfied: future in /srv/conda/envs/notebook/lib/python3.7/site-packages (from torch==1.6.0->torchvision==0.7.0) (0.18.2)\nInstalling collected packages: torchvision\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.11.2\n    Uninstalling torchvision-0.11.2:\n      Successfully uninstalled torchvision-0.11.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.5.3 requires torch<1.11,>=1.7.0, but you have torch 1.6.0 which is incompatible.\nfastai 2.5.3 requires torchvision>=0.8.2, but you have torchvision 0.7.0 which is incompatible.\u001b[0m\nSuccessfully installed torchvision-0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"path = untar_data(URLs.MNIST)","metadata":{"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.03% [15687680/15683414 00:01<00:00]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hide\nPath.BASE_PATH = path","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"path.ls()","metadata":{"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(#2) [Path('training'),Path('testing')]"},"metadata":{}}]},{"cell_type":"code","source":"(path/'training').ls()","metadata":{"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(#10) [Path('training/7'),Path('training/1'),Path('training/8'),Path('training/4'),Path('training/2'),Path('training/9'),Path('training/0'),Path('training/5'),Path('training/6'),Path('training/3')]"},"metadata":{}}]},{"cell_type":"code","source":"training = path/'training'\ntraining.ls().sorted()","metadata":{"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(#10) [Path('training/0'),Path('training/1'),Path('training/2'),Path('training/3'),Path('training/4'),Path('training/5'),Path('training/6'),Path('training/7'),Path('training/8'),Path('training/9')]"},"metadata":{}}]},{"cell_type":"code","source":"testing = path/'testing'\ntesting.ls().sorted()","metadata":{"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(#10) [Path('testing/0'),Path('testing/1'),Path('testing/2'),Path('testing/3'),Path('testing/4'),Path('testing/5'),Path('testing/6'),Path('testing/7'),Path('testing/8'),Path('testing/9')]"},"metadata":{}}]},{"cell_type":"code","source":"ones = (path/'training'/'1').ls().sorted()\ntwos = (path/'training'/'2').ls().sorted()\nthrees = (path/'training'/'3').ls().sorted()\nfours = (path/'training'/'4').ls().sorted()\nfives = (path/'training'/'5').ls().sorted()\nsixes = (path/'training'/'6').ls().sorted()\nsevens = (path/'training'/'7').ls().sorted()\neights = (path/'training'/'8').ls().sorted()\nnines = (path/'training'/'9').ls().sorted()\nzeros = (path/'training'/'0').ls().sorted()\nvalid_ones = (path/'testing'/'1').ls().sorted()\nvalid_twos = (path/'testing'/'2').ls().sorted()\nvalid_threes = (path/'testing'/'3').ls().sorted()\nvalid_fours = (path/'testing'/'4').ls().sorted()\nvalid_fives = (path/'testing'/'5').ls().sorted()\nvalid_sixes = (path/'testing'/'6').ls().sorted()\nvalid_sevens = (path/'testing'/'7').ls().sorted()\nvalid_eights = (path/'testing'/'8').ls().sorted()\nvalid_nines = (path/'testing'/'9').ls().sorted()\nvalid_zeros = (path/'testing'/'0').ls().sorted()\nones","metadata":{"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(#6742) [Path('training/1/10006.png'),Path('training/1/10007.png'),Path('training/1/1002.png'),Path('training/1/10020.png'),Path('training/1/10027.png'),Path('training/1/1003.png'),Path('training/1/10040.png'),Path('training/1/10048.png'),Path('training/1/10058.png'),Path('training/1/10067.png')...]"},"metadata":{}}]},{"cell_type":"code","source":"one_tensors = [tensor(Image.open(o)) for o in ones]\ntwo_tensors = [tensor(Image.open(o)) for o in twos]\nthree_tensors = [tensor(Image.open(o)) for o in threes]\nfour_tensors = [tensor(Image.open(o)) for o in fours]\nfive_tensors = [tensor(Image.open(o)) for o in fives]\nsix_tensors = [tensor(Image.open(o)) for o in sixes]\nseven_tensors = [tensor(Image.open(o)) for o in sevens]\neight_tensors = [tensor(Image.open(o)) for o in eights]\nnine_tensors = [tensor(Image.open(o)) for o in nines]\nzero_tensors = [tensor(Image.open(o)) for o in zeros]\nvalid_1_tensors = [tensor(Image.open(o)) for o in valid_ones]\nvalid_2_tensors = [tensor(Image.open(o)) for o in valid_twos]\nvalid_3_tensors = [tensor(Image.open(o)) for o in valid_threes]\nvalid_4_tensors = [tensor(Image.open(o)) for o in valid_fours]\nvalid_5_tensors = [tensor(Image.open(o)) for o in valid_fives]\nvalid_6_tensors = [tensor(Image.open(o)) for o in valid_sixes]\nvalid_7_tensors = [tensor(Image.open(o)) for o in valid_sevens]\nvalid_8_tensors = [tensor(Image.open(o)) for o in valid_eights]\nvalid_9_tensors = [tensor(Image.open(o)) for o in valid_nines]\nvalid_0_tensors = [tensor(Image.open(o)) for o in valid_zeros]\nlen(one_tensors)","metadata":{"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"6742"},"metadata":{}}]},{"cell_type":"code","source":"img1=one_tensors[1]\nshow_image(one_tensors[1]);","metadata":{"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 72x72 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"#hide\nstacked_ones = torch.stack(one_tensors).float()/255\nstacked_twos = torch.stack(two_tensors).float()/255\nstacked_threes = torch.stack(three_tensors).float()/255\nstacked_fours = torch.stack(four_tensors).float()/255\nstacked_fives = torch.stack(five_tensors).float()/255\nstacked_sixes = torch.stack(six_tensors).float()/255\nstacked_sevens = torch.stack(seven_tensors).float()/255\nstacked_eights = torch.stack(eight_tensors).float()/255\nstacked_nines = torch.stack(nine_tensors).float()/255\nstacked_zeros = torch.stack(zero_tensors).float()/255\nstacked_1_valid = torch.stack(valid_1_tensors).float()/255\nstacked_2_valid = torch.stack(valid_2_tensors).float()/255\nstacked_3_valid = torch.stack(valid_3_tensors).float()/255\nstacked_4_valid = torch.stack(valid_4_tensors).float()/255\nstacked_5_valid = torch.stack(valid_5_tensors).float()/255\nstacked_6_valid = torch.stack(valid_6_tensors).float()/255\nstacked_7_valid = torch.stack(valid_7_tensors).float()/255\nstacked_8_valid = torch.stack(valid_8_tensors).float()/255\nstacked_9_valid = torch.stack(valid_9_tensors).float()/255\nstacked_0_valid = torch.stack(valid_0_tensors).float()/255\nstacked_ones","metadata":{"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        ...,\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]])"},"metadata":{}}]},{"cell_type":"code","source":"train_x = torch.cat([stacked_ones, stacked_twos, stacked_threes, stacked_fours, stacked_fives, stacked_sixes, stacked_sevens, stacked_eights, stacked_nines, stacked_zeros]).view(-1, 28*28)\ntrain_y = tensor([1]*len(ones) + [2]*len(twos) + [3]*len(threes) + [4]*len(fours) + [5]*len(fives) + [6]*len(sixes) + [7]*len(sevens) + [8]*len(eights) + [9]*len(nines) + [0]*len(zeros)).unsqueeze(1)\ntrain_dset = list(zip(train_x,train_y))","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"x,y = train_dset[0]\nx.shape,y, len(train_dset)","metadata":{"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(torch.Size([784]), tensor([1]), 60000)"},"metadata":{}}]},{"cell_type":"code","source":"valid_x = torch.cat([stacked_1_valid, stacked_2_valid, stacked_3_valid, stacked_4_valid, stacked_5_valid, stacked_6_valid, stacked_7_valid, stacked_8_valid, stacked_9_valid, stacked_0_valid]).view(-1, 28*28)\nvalid_y = tensor([1]*len(stacked_1_valid) + [2]*len(stacked_2_valid) + [3]*len(stacked_3_valid) + [4]*len(stacked_4_valid) + [5]*len(stacked_5_valid) + [6]*len(stacked_6_valid) + [7]*len(stacked_7_valid) + [8]*len(stacked_8_valid) + [9]*len(stacked_9_valid) + [0]*len(stacked_0_valid)).unsqueeze(1)\ntest_dset = list(zip(valid_x,valid_y))\nx,y = test_dset[0]\nx.shape,y, len(test_dset)","metadata":{"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(torch.Size([784]), tensor([1]), 10000)"},"metadata":{}}]},{"cell_type":"code","source":"train_dl = DataLoader(train_dset, batch_size=256, shuffle=True)\nxb,yb = first(train_dl)\nxb.shape,yb.shape","metadata":{"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(torch.Size([256, 784]), torch.Size([256, 1]))"},"metadata":{}}]},{"cell_type":"code","source":"test_dl = DataLoader(test_dset, batch_size=256, shuffle=False)\nxb,yb = first(test_dl)\nxb.shape,yb.shape","metadata":{"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(torch.Size([256, 784]), torch.Size([256, 1]))"},"metadata":{}}]},{"cell_type":"code","source":"dls = DataLoaders(train_dl, test_dl)","metadata":{"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"s_net = nn.Sequential(\n    nn.Linear(28*28,30),\n    nn.ReLU(),\n    nn.Linear(30,10)\n    )","metadata":{"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"#loss_function1 = nn.CrossEntropyLoss()\nloss_f = CrossEntropyLossFlat()","metadata":{"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# check shape of model predictions one a single batch xb\nprediction_xb = model(xb)\nprediction_xb.shape","metadata":{"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"torch.Size([256, 10])"},"metadata":{}}]},{"cell_type":"code","source":"#learn = Learner(dls, model, opt_func=SGD, loss_func=loss_f, metrics=accuracy)\n#learn = Learner(dls, model,loss_func=loss_function1, metrics=accuracy)\nlearn = Learner(dls, s_net,loss_func=loss_f, metrics=accuracy)","metadata":{"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"learn.fit_one_cycle(5)\n#learn.fit(40, 0.1)\n#learn.fit_one_cycle(1, 0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.export()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s_net.load_state_dict(torch.load('output/model.pt'))\ndummy_input = Variable(torch.randn(1, 1, 28, 28)) \ntorch.onnx.export(trained_model, dummy_input, \"output/model.onnx\") ","metadata":{},"execution_count":null,"outputs":[]}]}